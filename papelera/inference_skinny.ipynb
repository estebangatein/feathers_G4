{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a7f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0428a584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# choose device, not recommended to train with 'cpu\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "914c5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_path = row[\"image_path\"]     # ya viene completo desde load_data()\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_test:\n",
    "            sample_id = int(row[\"id\"])\n",
    "            return image, sample_id\n",
    "\n",
    "        label = int(row[\"label\"])\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204f5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # reads csvs\n",
    "    train_df = pd.read_csv(\"aml-2025-feathers-in-focus/train_images.csv\")\n",
    "    test_df = pd.read_csv(\"aml-2025-feathers-in-focus/test_images_path.csv\")\n",
    "\n",
    "    # adjusts labels for the model\n",
    "    train_df[\"label\"] = train_df[\"label\"] - 1\n",
    "\n",
    "    # rewrite full image_path to have the correct folder\n",
    "    train_df[\"image_path\"] = \"aml-2025-feathers-in-focus/train_images/train_images/\" + train_df[\"image_path\"].str.split(\"/\").str[-1]\n",
    "    test_df[\"image_path\"] = \"aml-2025-feathers-in-focus/test_images/test_images/\" + test_df[\"image_path\"].str.split(\"/\").str[-1]\n",
    "\n",
    "    # print sizes\n",
    "    print(f\"Train: {len(train_df)} | Test: {len(test_df)}\")\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17313e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value='random'),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9965b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3926 | Test: 4000\n",
      "Train: 123\n",
      "Test: 125\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = load_data()\n",
    "\n",
    "train_ds = BirdDataset(train_df, transform=train_tfms, is_test=False)\n",
    "test_ds  = BirdDataset(test_df,  transform=test_tfms,  is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Train:\", len(train_loader))\n",
    "print(\"Test:\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cc3881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"Bloque residual simple sin SE (más ligero)\"\"\"\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = self.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet18Skinny(nn.Module):\n",
    "    def __init__(self, num_classes=200, dropout_rate=0.6):\n",
    "        super().__init__()\n",
    "        \n",
    "        # CAMBIO #1: Stem con menos canales\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=7, stride=2, padding=3, bias=False),  # 64 → 32\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # CAMBIO #2: Canales reducidos en layers\n",
    "        # Standard: 64, 128, 256, 512\n",
    "        # Skinny:   32, 64,  128, 256\n",
    "        self.layer1 = self._make_layer(32, 32, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(32, 64, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(64, 128, 2, stride=2) # instead of classic values (//2)\n",
    "        self.layer4 = self._make_layer(128, 256, 2, stride=2)\n",
    "        \n",
    "        # CAMBIO #3: Dropout agresivo + less params en FC\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(p=dropout_rate)  # 0.6 es agresivo\n",
    "        self.fc = nn.Linear(256, num_classes)      # 512 → 256\n",
    "        \n",
    "        # Inicialización\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
    "        layers = [BasicBlock(in_channels, out_channels, stride)]\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlock(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca8ee465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained \n",
    "model = ResNet18Skinny(num_classes=200)\n",
    "state_dict = torch.load(\"resnet18Skinny.pth\", map_location=torch.device(device))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415022b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:20<00:00,  6.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submission.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, ids in tqdm(test_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        preds = torch.argmax(logits, dim=1) + 1   # convertir 0–199 → 1–200\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            predictions.append({\n",
    "                \"id\": int(ids[i].item()),\n",
    "                \"label\": int(preds[i].item())\n",
    "            })\n",
    "\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv(\"submission_skinny.csv\", index=False)\n",
    "print(\"Predictions saved to submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
