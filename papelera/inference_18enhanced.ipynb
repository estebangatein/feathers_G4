{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94a7f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0428a584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# choose device, not recommended to train with 'cpu\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914c5e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, is_test=False):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_path = row[\"image_path\"]     # ya viene completo desde load_data()\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_test:\n",
    "            sample_id = int(row[\"id\"])\n",
    "            return image, sample_id\n",
    "\n",
    "        label = int(row[\"label\"])\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "204f5ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # reads csvs\n",
    "    train_df = pd.read_csv(\"aml-2025-feathers-in-focus/train_images.csv\")\n",
    "    test_df = pd.read_csv(\"aml-2025-feathers-in-focus/test_images_path.csv\")\n",
    "\n",
    "    # adjusts labels for the model\n",
    "    train_df[\"label\"] = train_df[\"label\"] - 1\n",
    "\n",
    "    # rewrite full image_path to have the correct folder\n",
    "    train_df[\"image_path\"] = \"aml-2025-feathers-in-focus/train_images/train_images/\" + train_df[\"image_path\"].str.split(\"/\").str[-1]\n",
    "    test_df[\"image_path\"] = \"aml-2025-feathers-in-focus/test_images/test_images/\" + test_df[\"image_path\"].str.split(\"/\").str[-1]\n",
    "\n",
    "    # print sizes\n",
    "    print(f\"Train: {len(train_df)} | Test: {len(test_df)}\")\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17313e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfms = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.RandomResizedCrop(224, scale=(0.7, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.RandomErasing(p=0.2, scale=(0.02, 0.2), ratio=(0.3, 3.3), value='random'),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_tfms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9965b8ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3926 | Test: 4000\n",
      "Train: 123\n",
      "Test: 125\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = load_data()\n",
    "\n",
    "train_ds = BirdDataset(train_df, transform=train_tfms, is_test=False)\n",
    "test_ds  = BirdDataset(test_df,  transform=test_tfms,  is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Train:\", len(train_loader))\n",
    "print(\"Test:\", len(test_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cc3881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# SE Block\n",
    "# ----------------------------\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(channels, channels // reduction)\n",
    "        self.fc2 = nn.Linear(channels // reduction, channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, h, w = x.size()\n",
    "        y = x.mean((2,3))              # Global Average Pooling\n",
    "        y = F.relu(self.fc1(y))\n",
    "        y = torch.sigmoid(self.fc2(y))\n",
    "        y = y.view(b, c, 1, 1)\n",
    "        return x * y\n",
    "\n",
    "# ----------------------------\n",
    "# Basic Residual Block con SE\n",
    "# ----------------------------\n",
    "class BasicBlockSE(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1, reduction=16):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride, 1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.se = SEBlock(out_channels, reduction)\n",
    "\n",
    "        # Identity / shortcut\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = self.shortcut(x)\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.se(out)         # SE block\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# ----------------------------\n",
    "# ResNet18 mejorado: Stem moderno + SE blocks\n",
    "# ----------------------------\n",
    "class ResNet18Enhanced(nn.Module):\n",
    "    def __init__(self, num_classes=200):\n",
    "        super().__init__()\n",
    "        # ----------------------------\n",
    "        # Stem moderno (3 convs en lugar de 7x7)\n",
    "        # ----------------------------\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, 3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, 3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2, padding=1)\n",
    "        )\n",
    "\n",
    "        # ----------------------------\n",
    "        # Bloques residuales con SE\n",
    "        # ----------------------------\n",
    "        self.layer1 = self._make_layer(64, 64, 2, stride=1)\n",
    "        self.layer2 = self._make_layer(64, 128, 2, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 2, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 2, stride=2)\n",
    "\n",
    "        # ----------------------------\n",
    "        # Clasificador\n",
    "        # ----------------------------\n",
    "        self.gap = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, blocks, stride):\n",
    "        layers = [BasicBlockSE(in_channels, out_channels, stride)]\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(BasicBlockSE(out_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.gap(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca8ee465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load pretrained \n",
    "model = ResNet18Enhanced(num_classes=200)\n",
    "state_dict = torch.load(\"resnet18_enhanced_best.pth\", map_location=torch.device(device))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "415022b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:31<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to submission_enhanced.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, ids in tqdm(test_loader):\n",
    "\n",
    "        images = images.to(device)\n",
    "\n",
    "        logits = model(images)\n",
    "        preds = torch.argmax(logits, dim=1) + 1   # convertir 0–199 → 1–200\n",
    "\n",
    "        for i in range(len(preds)):\n",
    "            predictions.append({\n",
    "                \"id\": int(ids[i].item()),\n",
    "                \"label\": int(preds[i].item())\n",
    "            })\n",
    "\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv(\"submission_enhanced.csv\", index=False)\n",
    "print(\"Predictions saved to submission_enhanced.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
