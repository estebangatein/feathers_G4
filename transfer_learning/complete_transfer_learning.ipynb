{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f9b4e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abec7cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "# choose device, not recommended to train with 'cpu\n",
    "\n",
    "device = (\n",
    "    \"cuda\" if torch.cuda.is_available()\n",
    "    else \"mps\" if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "501b9c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at Hemg/Birds-Species-classification and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([526]) in the checkpoint and torch.Size([200]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([526, 768]) in the checkpoint and torch.Size([200, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# obtain the models from HF\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"Hemg/Birds-Species-classification\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"Hemg/Birds-Species-classification\", num_labels=200, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "678c6e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdDataset(Dataset):\n",
    "    def __init__(self, df, processor, is_test=False):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.is_test = is_test\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image = Image.open(row[\"image_path\"]).convert(\"RGB\")\n",
    "        encoding = self.processor(image, return_tensors=\"pt\")\n",
    "        encoding = {k: v.squeeze(0) for k, v in encoding.items()}\n",
    "\n",
    "        if not self.is_test:\n",
    "            encoding[\"labels\"] = torch.tensor(int(row[\"label\"]))\n",
    "        else:\n",
    "            # Solo en test devolvemos el id\n",
    "            encoding[\"id\"] = torch.tensor(int(row[\"id\"]))\n",
    "\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c5beb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    # reads csvs\n",
    "    train_df = pd.read_csv(\"../aml-2025-feathers-in-focus/train_images.csv\")\n",
    "    test_df = pd.read_csv(\"../aml-2025-feathers-in-focus/test_images_path.csv\")\n",
    "\n",
    "    # adjusts labels for the model\n",
    "    train_df[\"label\"] = train_df[\"label\"] - 1\n",
    "\n",
    "    # rewrite full image_path to have the correct folder\n",
    "    train_df[\"image_path\"] = \"../aml-2025-feathers-in-focus/train_images/train_images/\" + train_df[\"image_path\"].str.split(\"/\").str[-1]\n",
    "    test_df[\"image_path\"] = \"../aml-2025-feathers-in-focus/test_images/test_images/\" + test_df[\"image_path\"].str.split(\"/\").str[-1]\n",
    "\n",
    "    # print sizes\n",
    "    print(f\"Train: {len(train_df)} | Test: {len(test_df)}\")\n",
    "    return train_df, test_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f3877c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 3926 | Test: 4000\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = load_data()\n",
    "\n",
    "train_ds = BirdDataset(train_df, processor)\n",
    "test_ds = BirdDataset(test_df, processor, is_test=True)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "28a7a8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters except the final layer\n",
    "for param in model.base_model.parameters():  # should check if 'base_model' is all but the classifier\n",
    "    param.requires_grad = False\n",
    "\n",
    "# only the parameters of the final layer will be trained\n",
    "for param in model.classifier.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58ab7988",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 [TRAIN]: 100%|██████████| 123/123 [02:28<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 4.0454 | Train Acc: 0.3576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 [TRAIN]: 100%|██████████| 123/123 [02:36<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 2.2532 | Train Acc: 0.5813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 [TRAIN]: 100%|██████████| 123/123 [02:55<00:00,  1.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 1.5858 | Train Acc: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 [TRAIN]: 100%|██████████| 123/123 [02:52<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 1.2737 | Train Acc: 0.7282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 [TRAIN]: 100%|██████████| 123/123 [02:50<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 1.0842 | Train Acc: 0.7723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 [TRAIN]: 100%|██████████| 123/123 [02:51<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.9535 | Train Acc: 0.7947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 [TRAIN]: 100%|██████████| 123/123 [02:51<00:00,  1.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.8499 | Train Acc: 0.8192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 [TRAIN]: 100%|██████████| 123/123 [02:50<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.7661 | Train Acc: 0.8329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 [TRAIN]: 100%|██████████| 123/123 [02:49<00:00,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 0.6994 | Train Acc: 0.8500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 [TRAIN]: 100%|██████████| 123/123 [02:49<00:00,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6417 | Train Acc: 0.8658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=5e-4)\n",
    "epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1} [TRAIN]\"):\n",
    "        # batch_id = batch.pop(\"id\") \n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        logits = outputs.logits\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # accumulate loss and accuracy\n",
    "        epoch_loss += loss.item() * logits.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == batch[\"labels\"]).sum().item()\n",
    "        total += logits.size(0)\n",
    "\n",
    "    epoch_loss /= total\n",
    "    epoch_acc = correct / total\n",
    "\n",
    "    train_losses.append(epoch_loss)\n",
    "    train_accuracies.append(epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed2769b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_model/preprocessor_config.json']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"saved_model\")\n",
    "processor.save_pretrained(\"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e32b9912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ViTForImageClassification(\n",
       "  (vit): ViTModel(\n",
       "    (embeddings): ViTEmbeddings(\n",
       "      (patch_embeddings): ViTPatchEmbeddings(\n",
       "        (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "      )\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (encoder): ViTEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ViTLayer(\n",
       "          (attention): ViTAttention(\n",
       "            (attention): ViTSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): ViTSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ViTIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ViTOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "  )\n",
       "  (classifier): Linear(in_features=768, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AutoModelForImageClassification.from_pretrained(\"saved_model\")\n",
    "processor = AutoImageProcessor.from_pretrained(\"saved_model\")\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2917f52e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Predictions saved to submission.csv'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        # Sacar ids y no enviarlos al modelo\n",
    "        batch_ids = batch.pop(\"id\")\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(**batch)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        # Predicciones (1-200)\n",
    "        preds = torch.argmax(logits, dim=1) + 1\n",
    "\n",
    "        # Guardar id y label\n",
    "        for i in range(len(preds)):\n",
    "            predictions.append({\n",
    "                \"id\": int(batch_ids[i].item()),  # tensor -> int\n",
    "                \"label\": int(preds[i].item())\n",
    "            })\n",
    "\n",
    "# Crear DataFrame y guardar CSV\n",
    "pred_df = pd.DataFrame(predictions)\n",
    "pred_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "(\"Predictions saved to submission.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
